{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv > /dev/null 2>&1\n",
    "%pip install datasets > /dev/null 2>&1\n",
    "%pip install nltk > /dev/null 2>&1\n",
    "%pip install openai > /dev/null 2>&1\n",
    "%pip install tenacity > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Translator\n",
    "\n",
    "Create various translator to translate sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "# Define the abstract translator class that will be implemented by the different translators\n",
    "# The translator class will have a translate method that will take a text, source language and target language and return the translated text\n",
    "class Translator(ABC):\n",
    "    @abstractmethod\n",
    "    def translate(self, text: str, source_lang:str, target_lang:str) -> str:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "\n",
    "class InvalidSystemPromptError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class AzureOpenAITranslator(Translator):\n",
    "    def __init__(\n",
    "        self,\n",
    "        endpoint: str,\n",
    "        subscription_key: str,\n",
    "        deployment: str,\n",
    "        api_version: str = \"2024-02-01\",\n",
    "        system_prompt: str = \"translate from <source_lang> to <target_lang>\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \n",
    "        if \"<source_lang>\" not in system_prompt or \"<target_lang>\" not in system_prompt:\n",
    "            raise InvalidSystemPromptError(\"system_prompt must contain <source_lang> and <target_lang> placeholders.\")\n",
    "         \n",
    "        self._translator = AzureOpenAI(\n",
    "            azure_endpoint=endpoint,\n",
    "            api_key=subscription_key,\n",
    "            api_version=api_version,\n",
    "            **kwargs,\n",
    "        )\n",
    "        self._deployment = deployment\n",
    "        self._system_prompt = system_prompt\n",
    "\n",
    "    @retry(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=10, min=10, max=60))\n",
    "    def translate(self, text: str, source_lang: str, target_lang: str) -> str:\n",
    "        response = self._translator.chat.completions.create(\n",
    "            model=self._deployment,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": self._system_prompt.replace(\n",
    "                        \"<source_lang>\", source_lang\n",
    "                    ).replace(\"<target_lang>\", target_lang),\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": text},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            response.choices[0].message.content\n",
    "            if response.choices[0].message.content is not None\n",
    "            else \"\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Benchmark Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Literal\n",
    "\n",
    "# Define the abstract evaluator class that will be implemented by the different evaluators\n",
    "# The evaluator class will have a score method that will take a list of references and a list of candidates and return the score\n",
    "class Evaluator(ABC):\n",
    "    @abstractmethod\n",
    "    def score(self, references: list[str], candidate: str) -> list[int] | Literal[0]:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from typing import Literal\n",
    "\n",
    "class BLEUSentenceEvaluator(Evaluator):\n",
    "    def __init__(self, smoothing_function = SmoothingFunction().method1, weights: tuple[float, float, float, float] = (0.25, 0.25, 0.25, 0.25)):\n",
    "        # Smoothing function is used to avoid the warning message when the candidate is empty and the BLEU score is 0\n",
    "        # This is because the smoothing function will smooth the 0 score to a very small positive value\n",
    "        self._smoothing_function = smoothing_function\n",
    "        self._weights = weights\n",
    "        pass\n",
    "\n",
    "    def score(self, references: list[str], candidate: str) -> list[int] | Literal[0]:\n",
    "\n",
    "        reference = [ref.split() for ref in references]\n",
    "        candidates = candidate.split()\n",
    "\n",
    "        return sentence_bleu(reference, candidates, smoothing_function=self._smoothing_function, weights=self._weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Translation Funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function that will evaluate the translation\n",
    "def evaluate_translation(translator: Translator, evaluator: Evaluator, source_text: str, source_lang: str, target_lang: str, references: list[str], verbose: bool = False):\n",
    "    translated_text = translator.translate(source_text, source_lang, target_lang)\n",
    "    score = evaluator.score(references, translated_text)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Source Text: {source_text}\")\n",
    "        print(f\"Translated Text: {translated_text}\")\n",
    "        print(f\"BLEU Score: {score}\")\n",
    "\n",
    "    return score, translated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Load Dataset\n",
    "\n",
    "Load dataset from huggingface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets.config\n",
    "import os\n",
    "\n",
    "# Set the cache directory\n",
    "cache_dir = os.path.join(os.getcwd(), '.cache/')\n",
    "\n",
    "if not os.path.exists(cache_dir):\n",
    "    os.makedirs(cache_dir)\n",
    "\n",
    "datasets.config.HF_DATASETS_CACHE = cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['conversations_vi', 'conversations_en'],\n",
      "        num_rows: 9171\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"5CD-AI/Vietnamese-mahiatlinux-Reflection-Dataset-ShareGPT-v2-gg-translated\")\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "azure_translator = AzureOpenAITranslator(\n",
    "    endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\", \"\"),\n",
    "    subscription_key=os.environ.get(\"AZURE_OPENAI_KEY\", \"\"),\n",
    "    deployment=\"gpt-4o\", # change your deployment here, and make sure it is available in your Azure OpenAI account\n",
    ")\n",
    "\n",
    "evaluator = BLEUSentenceEvaluator()\n",
    "\n",
    "total_score = 0\n",
    "for i in range(5):\n",
    "    source_text = ds[\"train\"][i][\"conversations_en\"][0][\"value\"]\n",
    "    source_lang = \"en\"\n",
    "    target_lang = \"vi\"\n",
    "    references = [ds[\"train\"][i][\"conversations_vi\"][0][\"value\"]]\n",
    "\n",
    "    score, translated = evaluate_translation(azure_translator, evaluator, source_text, source_lang, target_lang, references)\n",
    "\n",
    "    if isinstance(score, list):\n",
    "        total_score += sum(score)\n",
    "    else:\n",
    "        total_score += score\n",
    "\n",
    "print(f\"Average BLEU Score: {total_score/5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
