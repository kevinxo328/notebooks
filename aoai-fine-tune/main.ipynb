{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv > /dev/null 2>&1\n",
    "%pip install datasets > /dev/null 2>&1\n",
    "%pip install openai > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Create Data for Training\n",
    "\n",
    "Load a dataset from a local file and create data to fine-tune Azure OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3 examples [00:00, 415.69 examples/s]\n",
      "Generating test split: 2 examples [00:00, 804.82 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['user', 'assistant'],\n",
      "        num_rows: 3\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['user', 'assistant'],\n",
      "        num_rows: 2\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import re\n",
    "import os\n",
    "\n",
    "train_file = \"./training_example.csv\" # Path to the data file, replace with the correct path\n",
    "test_file = \"./testing_example.csv\" # Path to the data file, replace with the correct path\n",
    "ds = load_dataset('csv', data_files={\n",
    "    'train': train_file,\n",
    "    'test': test_file\n",
    "}, delimiter=',')\n",
    "print(ds)\n",
    "\n",
    "def sanitize_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Sanitize the text by removing extra spaces and newlines.\n",
    "    \"\"\"\n",
    "    text = text.strip()\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "\n",
    "    # remove \" and ' from the text\n",
    "    text = text.replace('\"', \"\")\n",
    "    text = text.replace(\"'\", \"\")\n",
    "\n",
    "    return text\n",
    "\n",
    "def prepare_training_data(key:str):\n",
    "    \"\"\"\n",
    "    Prepare the training data by sanitizing the text and creating the training data.\n",
    "    \"\"\"\n",
    "    training_data = []\n",
    "    for example in ds[key]:\n",
    "        user_input = example['user'] # Replace with the correct column name\n",
    "        assistant_response = example['assistant'] # Replace with the correct column name\n",
    "        system_prompt = \"\"\"\n",
    "        You are an Xbox customer support agent whose primary goal is to help users with issues they are experiencing with their Xbox devices. You are friendly and concise. You only provide factual answers to queries, and do not provide answers that are not related to Xbox.\n",
    "        \"\"\"\n",
    "\n",
    "        training_data.append({\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": sanitize_text(system_prompt)},\n",
    "                {\"role\": \"user\", \"content\": sanitize_text(user_input)},\n",
    "                {\"role\": \"assistant\", \"content\": sanitize_text(assistant_response)}\n",
    "            ]\n",
    "        })\n",
    "    \n",
    "    data_dir = os.path.join(os.getcwd(), 'training_data')\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "\n",
    "    # Save the training data to a jsonl file, replace ' with \"\n",
    "    with open(os.path.join(data_dir, f\"{key}.jsonl\"), \"w\") as f:\n",
    "        for data in training_data:\n",
    "            f.write(str(data).replace(\"'\", \"\\\"\") + \"\\n\")\n",
    "\n",
    "prepare_training_data('train')\n",
    "prepare_training_data('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data to Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\",\"\"), \n",
    "  api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\",\"\"),  \n",
    "  api_version=\"2024-05-01-preview\"  # This API version or later is required to access seed/events/checkpoint capabilities\n",
    ")\n",
    "\n",
    "training_file_name = os.path.join(os.getcwd(), 'training_data', 'train.jsonl')\n",
    "validation_file_name = os.path.join(os.getcwd(), 'training_data', 'test.jsonl')\n",
    "\n",
    "# Upload the training and validation dataset files to Azure OpenAI with the SDK.\n",
    "\n",
    "training_response = client.files.create(\n",
    "    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "training_file_id = training_response.id\n",
    "\n",
    "validation_response = client.files.create(\n",
    "    file=open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "validation_file_id = validation_response.id\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Fine-Tune Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=\"gpt-35-turbo-0613\", # Enter base model name. Note that in Azure OpenAI the model name contains dashes and cannot contain dot/period characters. \n",
    "    seed = 105  # seed parameter controls reproducibility of the fine-tuning job. If no seed is specified one will be generated automatically.\n",
    ")\n",
    "\n",
    "job_id = response.id\n",
    "\n",
    "# You can use the job ID to monitor the status of the fine-tuning job.\n",
    "# The fine-tuning job will take some time to start and complete.\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.id)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Fine-Tune Job Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
